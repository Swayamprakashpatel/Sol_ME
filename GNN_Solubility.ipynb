{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCnjwTt9jiQSsc/h+bPdiy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swayamprakashpatel/Sol_ME/blob/main/GNN_Solubility.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMILE to Graph Neural Network for SOluhbilty Prediction"
      ],
      "metadata": {
        "id": "UieB0OXzSOlw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGZSI2smSHLp"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit-pypi tensorflow tensorflow-addons\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi tensorflow tensorflow-addons pubchempy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q-W97Z7TwQ8",
        "outputId": "e2029c6a-0935-45b6-ca51-cbcf8333ad7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: pubchempy in /usr/local/lib/python3.10/dist-packages (1.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pubchempy"
      ],
      "metadata": {
        "id": "KRO8bZ5pTdYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pubchempy as pcp\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input, Add\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/GNN.csv')\n",
        "\n",
        "# Function to convert PubChem CID to SMILES\n",
        "def cid_to_smiles(cid):\n",
        "    try:\n",
        "        compound = pcp.Compound.from_cid(cid)\n",
        "        return compound.canonical_smiles\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting CID {cid}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Convert CIDs to SMILES in the dataset\n",
        "df['drug_smiles'] = df['drug_cid'].apply(cid_to_smiles)\n",
        "df['solvent_smiles'] = df['solvent_cid'].apply(cid_to_smiles)\n",
        "\n",
        "# Function to convert SMILES to a graph\n",
        "def smiles_to_graph(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    AllChem.Compute2DCoords(mol)\n",
        "    atoms = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "    edges = []\n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        edges.append((i, j))\n",
        "        edges.append((j, i))\n",
        "    atom_features = np.array(atoms, dtype=np.float32).reshape(-1, 1)\n",
        "    edge_index = np.array(edges, dtype=np.int32)\n",
        "    return atom_features, edge_index\n",
        "\n",
        "# Process dataset into graph objects\n",
        "data_list = []\n",
        "solubilities = []\n",
        "for index, row in df.iterrows():\n",
        "    drug_graph = smiles_to_graph(row['drug_smiles'])\n",
        "    solvent_graph = smiles_to_graph(row['solvent_smiles'])\n",
        "    if drug_graph is not None and solvent_graph is not None:\n",
        "        data_list.append(drug_graph)\n",
        "        solubilities.append(row['solubility'])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "split_index = int(0.8 * len(data_list))\n",
        "train_data = data_list[:split_index]\n",
        "train_labels = solubilities[:split_index]\n",
        "test_data = data_list[split_index:]\n",
        "test_labels = solubilities[split_index:]\n",
        "\n",
        "# Custom GCN Layer\n",
        "class GraphConvolution(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[0][-1], self.units),\n",
        "                                      initializer='glorot_uniform',\n",
        "                                      trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        features, adj = inputs\n",
        "        return tf.matmul(adj, tf.matmul(features, self.kernel))\n",
        "\n",
        "# Define the GNN model using custom GCN layers\n",
        "def create_gnn_model(input_shape):\n",
        "    features = Input(shape=(input_shape[1], 1))\n",
        "    adj = Input(shape=(input_shape[1], input_shape[1]))\n",
        "\n",
        "    x = GraphConvolution(16)([features, adj])\n",
        "    x = tf.nn.relu(x)\n",
        "    x = GraphConvolution(32)([x, adj])\n",
        "    x = tf.nn.relu(x)\n",
        "    x = GraphConvolution(1)([x, adj])\n",
        "    x = Flatten()(x)\n",
        "    output = Dense(1)(x)\n",
        "\n",
        "    model = Model(inputs=[features, adj], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Prepare data for training\n",
        "def prepare_data(data_list, labels):\n",
        "    atom_features = [data[0] for data in data_list]\n",
        "    edge_indices = [data[1] for data in data_list]\n",
        "    num_nodes = max([features.shape[0] for features in atom_features])\n",
        "\n",
        "    atom_features_padded = []\n",
        "    adj_matrices = []\n",
        "\n",
        "    for i in range(len(atom_features)):\n",
        "        feature_padded = np.zeros((num_nodes, 1))\n",
        "        feature_padded[:atom_features[i].shape[0], :] = atom_features[i]\n",
        "        atom_features_padded.append(feature_padded)\n",
        "\n",
        "        adj_matrix = np.zeros((num_nodes, num_nodes))\n",
        "        for edge in edge_indices[i]:\n",
        "            adj_matrix[edge[0], edge[1]] = 1.0\n",
        "        adj_matrices.append(adj_matrix)\n",
        "\n",
        "    atom_features_padded = np.array(atom_features_padded, dtype=np.float32)\n",
        "    adj_matrices = np.array(adj_matrices, dtype=np.float32)\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "\n",
        "    return atom_features_padded, adj_matrices, labels\n",
        "\n",
        "train_atom_features, train_adj_matrices, train_labels = prepare_data(train_data, train_labels)\n",
        "test_atom_features, test_adj_matrices, test_labels = prepare_data(test_data, test_labels)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_gnn_model(train_atom_features.shape)\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "model.fit([train_atom_features, train_adj_matrices], train_labels, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "test_loss = model.evaluate([test_atom_features, test_adj_matrices], test_labels, verbose=0)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('gnn_model_tf.h5')\n"
      ],
      "metadata": {
        "id": "IKFv9fdYTSyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow_addons.layers import GCNConv\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('path_to_your_dataset.csv')\n",
        "\n",
        "# Function to convert SMILES to a graph\n",
        "def smiles_to_graph(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    AllChem.Compute2DCoords(mol)\n",
        "    atoms = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "    edges = []\n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        edges.append((i, j))\n",
        "        edges.append((j, i))\n",
        "    atom_features = np.array(atoms, dtype=np.float32).reshape(-1, 1)\n",
        "    edge_index = np.array(edges, dtype=np.int32)\n",
        "    return atom_features, edge_index\n",
        "\n",
        "# Process dataset into graph objects\n",
        "data_list = []\n",
        "solubilities = []\n",
        "for index, row in df.iterrows():\n",
        "    drug_graph = smiles_to_graph(row['drug_smiles'])\n",
        "    solvent_graph = smiles_to_graph(row['solvent_smiles'])\n",
        "    if drug_graph is not None and solvent_graph is not None:\n",
        "        data_list.append(drug_graph)\n",
        "        solubilities.append(row['solubility'])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "split_index = int(0.8 * len(data_list))\n",
        "train_data = data_list[:split_index]\n",
        "train_labels = solubilities[:split_index]\n",
        "test_data = data_list[split_index:]\n",
        "test_labels = solubilities[split_index:]\n",
        "\n",
        "# Define the GNN model using TensorFlow Sequential API\n",
        "def create_gnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(GCNConv(16, activation='relu'))\n",
        "    model.add(GCNConv(32, activation='relu'))\n",
        "    model.add(GCNConv(1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "model = create_gnn_model()\n",
        "\n",
        "# Prepare data for training\n",
        "def prepare_data(data_list, labels):\n",
        "    atom_features = [data[0] for data in data_list]\n",
        "    edge_indices = [data[1] for data in data_list]\n",
        "    atom_features = tf.ragged.constant(atom_features, dtype=tf.float32)\n",
        "    edge_indices = tf.ragged.constant(edge_indices, dtype=tf.int32)\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    return atom_features, edge_indices, labels\n",
        "\n",
        "train_atom_features, train_edge_indices, train_labels = prepare_data(train_data, train_labels)\n",
        "test_atom_features, test_edge_indices, test_labels = prepare_data(test_data, test_labels)\n",
        "\n",
        "# Training loop\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.fit([train_atom_features, train_edge_indices], train_labels, batch_size=batch_size, epochs=1, verbose=1)\n",
        "    test_loss = model.evaluate([test_atom_features, test_edge_indices], test_labels, verbose=0)\n",
        "    print(f'Epoch {epoch+1}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('gnn_model_tf.h5')\n"
      ],
      "metadata": {
        "id": "mUCr2FaFSKcE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}